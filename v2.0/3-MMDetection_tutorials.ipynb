{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/mmdet-logo.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMDetection 2.0 Tutorials\n",
    "\n",
    "<a href=\"\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MMClassification 2.0 Repo**：[https://github.com/open-mmlab/mmdetection/tree/3.x](https://github.com/open-mmlab/mmdetection/tree/3.x)\n",
    "\n",
    "**MMClassification 官方文档链接**：[https://mmdetection.readthedocs.io/en/3.x/index.html](https://mmdetection.readthedocs.io/en/3.x/index.html)\n",
    "\n",
    "**MMClassification 2.0 教学视频**：Coming Soon~\n",
    "\n",
    "**MMClassification 2.0 代码库介绍视频**：Coming Sonn~\n",
    "\n",
    "**加入微信社群方式**：关注公众号，选择 “加入我们” -> “微信社区”，即可获取入群二维码。非常期待你的到来呀~\n",
    "\n",
    "**作者**：OpenMMLab\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "0. Installation\n",
    "1. Inference\n",
    "2. Training\n",
    "3. Testing\n",
    "4. Training on Custom Datasets\n",
    "5. Useful Tools\n",
    "6. Model Deployment\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1. 加载预置环境**\n",
    "\n",
    "我们已经在集群上预装了 OpenMMLab 2.0 环境，使用见 [1-SetupEnvironment.md#1-使用预置环境](1-SetupEnvironment.md#1-使用预置环境)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2. 下载 MMDetection 源码**\n",
    "\n",
    "虽然环境里面预装了一系列工具包，但我们也可以使用github上最新的代码。例如可以通过以下方式“覆盖”预装的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用国内的镜像\n",
    "!git clone https://gitee.com/open-mmlab/mmdetection.git -b 3.x\n",
    "# 重要，保证使用的是 clone 下来的版本\n",
    "%cd mmdetection\n",
    "# 重要，确保是 v2.0 版本\n",
    "!git checkout 3.x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3. 查看安装是否正确**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmdet\n",
    "print(mmdet.__version__)\n",
    "print(mmdet.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inference \n",
    "用 MMDetection [模型库](https://mmdetection.readthedocs.io/en/3.x/model_zoo.html)中预训练好的模型对图片进行预测。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1. 准备一张图片 `mmdet-demo.jpg`**\n",
    "\n",
    "<img src=\"img/mmdet-demo.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2. 下载模型以及对应的配置文件**\n",
    "\n",
    "```bash\n",
    "mim download ${PACKAGE} ${CONFIG_FILENAME} --dest ${DESTINATION_PATH}\n",
    "```\n",
    "\n",
    "训练工具 `mim download` 参数讲解：\n",
    "\n",
    "+ PACKAGE：工具包名\n",
    "+ CONFIG_FILENAME：配置文件的文件名。**注意：不要加 `.py`**\n",
    "+ DESTINATION_PATH：下载文件保存路径\n",
    "\n",
    "更多请参考：[链接](https://openmim.readthedocs.io/en/latest/api.html#module-mim.commands.download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mim download mmdet --config rtmdet_s_8xb32-300e_coco --dest tutorial/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3. 用工具进行预测，解析推理结果 `result`，并可视化预测结果**\n",
    "\n",
    "```bash\n",
    "python demo/image_demo.py \\\n",
    "    ${IMG_PATH} \\\n",
    "    ${CONFIG_FILE} \\\n",
    "    ${CHECKPOINT_PATH} \\\n",
    "    [--device ${YOUR_DEVICE}] \\\n",
    "    [--out-file ${OUTPUT_PATH}] \\\n",
    "    [--palette ${coco,voc,citys,random,none}] \\\n",
    "    [--score-thr ${THRESHOLD_SCORE}]\n",
    "```\n",
    "\n",
    "推理工具 [demo/image_demo.py](https://github.com/open-mmlab/mmclassification/blob/1.x/demo/image_demo.py) 参数讲解:\n",
    "+ IMG_PATH：测试图片所在路径\n",
    "\n",
    "+ CONFIG_FILE：配置文件所在路径\n",
    "\n",
    "+ CHECKPOINT_PATH：模型文件所在路径\n",
    "\n",
    "+ device：设备，默认 'cuda:0'\n",
    "\n",
    "+ out-file : 输出文件路径及文件名\n",
    "\n",
    "+ palette : 可视化颜色方案选择\n",
    "\n",
    "+ score-thr : 检测框阈值设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在管理节点用 CPU执行\n",
    "!python demo/image_demo.py demo/demo.jpg tutorial/rtmdet_s_8xb32-300e_coco.py --weights tutorial/rtmdet_s_8xb32-300e_coco_20220905_161602-387a891e.pth --out-dir tutorial/demo/ --device cpu\n",
    "# 在GPU节点执行\n",
    "!srun -p gpu -n 1 --gres gpu:1 python demo/image_demo.py demo/demo.jpg tutorial/rtmdet_s_8xb32-300e_coco.py --weights tutorial/rtmdet_s_8xb32-300e_coco_20220905_161602-387a891e.pth --out-dir tutorial/demo/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training\n",
    "用 MMDetection 在 Pascal VOC 2007 & 2012 数据集上训练检测模型 RetinaNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1. 准备数据集**\n",
    "\n",
    "[Pascal VOC 2007](http://host.robots.ox.ac.uk/pascal/VOC/voc2007/) 数据集包含 20 个类别共 9963 张图片，其中 5011 张作为训练图片，4952 张作为测试图片。\n",
    "\n",
    "<img src=\"img/Pascal_VOC_2007_dataset.png\">\n",
    "\n",
    "我们推荐在 MMDetection 代码库的根目录下新建名为 `data` 的文件夹，并把数据集放在 `data` 文件夹里。\n",
    "\n",
    "MMDetection 提供了数据集[下载脚本](https://github.com/open-mmlab/mmdetection/blob/3.x/tools/misc/download_dataset.py)\n",
    "\n",
    "```bash\n",
    "python tools/misc/download_dataset.py \\\n",
    "    [--dataset-name ${DATASET_NAME}] \\\n",
    "    [--save-dir ${SAVING_DIRECTORY}] \\\n",
    "    [--unzip ${WHETHER_UNZIP}] \\\n",
    "    [--delete ${DELETE_DOWNLOAD_FILE}]\n",
    "```\n",
    "\n",
    "参数讲解:\n",
    "\n",
    "+ dataset-name：数据集名称，默认为 coco2017\n",
    "\n",
    "+ save-dir : 存储路径，默认为 data/coco\n",
    "\n",
    "+ unzip : 是否解压缩下载文件\n",
    "\n",
    "+ delete : 是否删除下载的压缩文件\n",
    "\n",
    "更多准备数据集的详情请参考：[链接](https://mmdetection.readthedocs.io/en/3.x/user_guides/dataset_prepare.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python tools/misc/download_dataset.py --dataset-name voc2007 --save-dir data --unzip\n",
    "# 集群上已经下载，位于 /cluster/share/VOCdevkit/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于下载工具还不支持 Pascal VOC 2012，需访问 [Pascal VOC 2012 官网](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/)自行下载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了简化数据准备流程，建议使用集群上已经下载的版本，通过符号链接链接到 data 文件夹下\n",
    "!mkdir -p ~/mmdetection/data\n",
    "!ln -s /cluster/share/VOCdevkit/ ~/mmdetection/data/VOCdevkit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2. 准备 RetinaNet 模型的配置文件**\n",
    "\n",
    "模型配置文件 `retinanet_r50_fpn_1x_voc0712.py` 包含在源代码中，位于 `configs/pascal_voc/` 下"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3. 解读配置文件** \n",
    "\n",
    "+ param_scheduler：参数调度器\n",
    "+ optim_wrapper：优化器\n",
    "+ train_cfg、val_cfg、test_cfg：训练、验证和测试的循环设置，比如训练多少个 epoch `max_epochs` 等等\n",
    "+ auto_scale_lr : 自动设置学习率\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4. 用工具开始训练**\n",
    "\n",
    "```bash\n",
    "mim train ${PACKAGE} ${CONFIG_FILE} --gpus ${GPUS}\n",
    "```\n",
    "\n",
    "训练工具 `mim train` 参数讲解：\n",
    "\n",
    "+ PACKAGE：工具包名\n",
    "+ CONFIG_FILE：配置文件所在路径\n",
    "+ GPUS：使用 GPU 的数量，默认值为 1\n",
    "\n",
    "更多请参考：[链接](https://openmim.readthedocs.io/en/latest/api.html#module-mim.commands.train)\n",
    "\n",
    "\n",
    "我们复现训练的结果：\n",
    "+ Epoch 1's mAP：0.063\n",
    "+ Epoch 2's mAP：0.353\n",
    "+ Epoch 3's mAP：0.552\n",
    "+ Epoch 4's mAP：0.649"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仅支持下载源码后使用\n",
    "# 单卡训练\n",
    "!srun -p gpu -N 1 -n 1 -c 4 --gres gpu:1 python -u tools/train.py configs/pascal_voc/retinanet_r50_fpn_1x_voc0712.py --auto-scale-lr\n",
    "# 多卡训练\n",
    "!srun -p gpu -N 1 -n 2 -c 4 --gres gpu:2 python -u tools/train.py configs/pascal_voc/retinanet_r50_fpn_1x_voc0712.py --auto-scale-lr --launcher slurm\n",
    "\n",
    "# 下载或没下载源码都可使用、多卡训练\n",
    "!mim train mmdet -l slurm -g 2 -G 2 -c 4 -p gpu configs/pascal_voc/retinanet_r50_fpn_1x_voc0712.py --auto-scale-lr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5. 理解打印出来的 log 日志文件**\n",
    "+ 系统环境\n",
    "+ 配置文件\n",
    "+ 训练过程中学习率的变化、loss 变化、消耗时间、消耗内存\n",
    "+ 验证集上的准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing\n",
    "用 MMDetection 在 Pascal VOC 2007 & 2012 数据集上测试分类模型 RetinaNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1. 准备数据集**\n",
    "\n",
    "我们依旧使用 [Pascal VOC 2007 & 2012](http://host.robots.ox.ac.uk/pascal/VOC/) 数据集来演示"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2. 下载 RetinaNet 模型以及对应的配置文件**\n",
    "\n",
    "+ 使用上一节准备好的 RetinaNet 配置文件\n",
    "\n",
    "+ 并下载对应的 RetinaNet  模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P tutorial https://download.openmmlab.com/mmdetection/v2.0/pascal_voc/retinanet_r50_fpn_1x_voc0712/retinanet_r50_fpn_1x_voc0712_20200617-47cbdd0e.pth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3. 用工具开始测试**\n",
    "\n",
    "```bash\n",
    "mim test ${PACKAGE} ${CONFIG_FILE} --checkpoint ${CHECKPOINT_FILE} --out ${DUMP_FILE}\n",
    "```\n",
    "\n",
    "训练工具 `mim test` 参数讲解：\n",
    "\n",
    "+ PACKAGE：工具包名\n",
    "+ CONFIG_FILE：配置文件所在路径\n",
    "+ CHECKPOINT_FILE：模型文件所在路径\n",
    "+ OTHER_ARGS: 其他和各自工具包（代码库）相关的参数。比如 MMDetection 中的\n",
    "    + DUMP_FILE：保存模型对每个样本的预测结果文件所在路径。默认不设置该参数，也就是不会保存该文件。如果要保存该文件，文件命名必须以 .pkl 为后缀\n",
    "\n",
    "\n",
    "更多请参考：[链接](https://openmim.readthedocs.io/en/latest/api.html#module-mim.commands.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载了源码，2卡测试\n",
    "!srun -p gpu -N 1 -n 2 -c 4 --gres gpu:2 python -u tools/test.py configs/pascal_voc/retinanet_r50_fpn_1x_voc0712.py tutorial/retinanet_r50_fpn_1x_voc0712_20200617-47cbdd0e.pth --out tutorial/result_voc.pkl --launcher slurm\n",
    "# 没下载源码，2卡测试\n",
    "!mim test mmdet -l slurm -g 2 -G 2 -c 4 -p gpu configs/pascal_voc/retinanet_r50_fpn_1x_voc0712.py --checkpoint tutorial/retinanet_r50_fpn_1x_voc0712_20200617-47cbdd0e.pth --out tutorial/result_voc.pkl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解读评估设置与结果**\n",
    "\n",
    "```python\n",
    "val_evaluator = dict(type='VOCMetric', metric='mAP', eval_mode='11points')\n",
    "test_evaluator = val_evaluator\n",
    "```\n",
    "Pascal VOC 2007 使用 `11points` 作为默认的评估模式，而Pascal VOC 2012 默认使用 `area`\n",
    "\n",
    "除了 `recall`、`AP`、`mAP`等，MMDetection 还支持许多其他评估指标（详情请参考：[链接](hhttps://mmdetection.readthedocs.io/en/3.x/api.html#mmdet-evaluation)），我们只需要修改配置文件中的 `val_evaluator` 和 `test_evaluator` 里的内容即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7GrWIJywLV-V"
   },
   "source": [
    "## 4. Train on Custom Datasets\n",
    "\n",
    "使用自定义数据集训练一个新的检测模型通常有三个步骤：\n",
    "1. 准备一个自定义数据集\n",
    "2. 准备一个配置文件\n",
    "3. 在自定义数据集上完成训练\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "E73y5Lru-wBx"
   },
   "source": [
    "**Step 1. 准备数据集**\n",
    "\n",
    "演示使用的自定义数据集为[balloon dataset](https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon)\n",
    "\n",
    "MMDetection支持三种自定义数据集的准备方式：\n",
    "\n",
    "+ 将自定义数据集转换为COCO格式\n",
    "+ 将自定义数据集转换为中间格式\n",
    "+ 实现一个新的数据集\n",
    "\n",
    "前两种方式通常会比第三种方式简单，因此建议使用前两种方式\n",
    "\n",
    "在这个例子中，我们将转换为COCO格式\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载balloon数据集放入data文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 集群上已经下载该数据集，位于 /cluster/share/balloon/ 下，不需要重复下载解压\n",
    "# !wget -P data https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解压缩balloon数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 集群上已经下载该数据集，位于 /cluster/share/balloon/ 下，可以不需要重复下载解压\n",
    "!unzip /cluster/share/balloon/balloon_dataset.zip -d data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了减轻网络负担，建议使用集群上已经下载的版本，解压到 data 文件夹下\n",
    "# !mkdir -p ~/mmdetection/data\n",
    "# !ln -s /cluster/share/balloon/ ~/mmdetection/data/balloon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看balloon数据集的目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get install tree # 如果环境中没有 tree 才需要安装\n",
    "!tree -d data/ballon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看balloon数据集中的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "YnQQqzOWzE91",
    "outputId": "baf6a89b-dbb2-4212-9e34-7055a9e2574c"
   },
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = mmcv.imread('data/balloon/train/120853323_d4788431b9_b.jpg')\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(mmcv.bgr2rgb(img))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看balloon数据集的标注格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n7rwalnPd6e1",
    "outputId": "54bfbfa4-463b-45a0-f77c-a80557c1bd69"
   },
   "outputs": [],
   "source": [
    "!cat data/balloon/train/via_region_data.json | python -m json.tool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对比COCO标注格式\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"images\": [image],\n",
    "    \"annotations\": [annotation],\n",
    "    \"categories\": [category]\n",
    "}\n",
    "\n",
    "image = {\n",
    "    \"id\": int,\n",
    "    \"width\": int,\n",
    "    \"height\": int,\n",
    "    \"file_name\": str,\n",
    "}\n",
    "\n",
    "annotation = {\n",
    "    \"id\": int,\n",
    "    \"image_id\": int,\n",
    "    \"category_id\": int,\n",
    "    \"segmentation\": RLE or [polygon],\n",
    "    \"area\": float,\n",
    "    \"bbox\": [x,y,width,height], # (x, y) are the coordinates of the upper left corner of the bbox\n",
    "    \"iscrowd\": 0 or 1,\n",
    "}\n",
    "\n",
    "categories = [{\n",
    "    \"id\": int,\n",
    "    \"name\": str,\n",
    "    \"supercategory\": str,\n",
    "}]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新建一个 balloon 数据转换文件 `balloon_converter.py` 粘贴代码并运行，将 balloon 数据集原有标注转换为 COCO 的标注格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch tutorial/balloon_converter.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import mmcv\n",
    "\n",
    "from mmengine.fileio import dump, load\n",
    "from mmengine.utils import track_iter_progress\n",
    "\n",
    "\n",
    "def convert_balloon_to_coco(ann_file, out_file, image_prefix):\n",
    "    data_infos = load(ann_file)\n",
    "\n",
    "    annotations = []\n",
    "    images = []\n",
    "    obj_count = 0\n",
    "    for idx, v in enumerate(track_iter_progress(data_infos.values())):\n",
    "        filename = v['filename']\n",
    "        img_path = osp.join(image_prefix, filename)\n",
    "        height, width = mmcv.imread(img_path).shape[:2]\n",
    "\n",
    "        images.append(\n",
    "            dict(id=idx, file_name=filename, height=height, width=width))\n",
    "\n",
    "        for _, obj in v['regions'].items():\n",
    "            assert not obj['region_attributes']\n",
    "            obj = obj['shape_attributes']\n",
    "            px = obj['all_points_x']\n",
    "            py = obj['all_points_y']\n",
    "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
    "            poly = [p for x in poly for p in x]\n",
    "\n",
    "            x_min, y_min, x_max, y_max = (min(px), min(py), max(px), max(py))\n",
    "\n",
    "            data_anno = dict(\n",
    "                image_id=idx,\n",
    "                id=obj_count,\n",
    "                category_id=0,\n",
    "                bbox=[x_min, y_min, x_max - x_min, y_max - y_min],\n",
    "                area=(x_max - x_min) * (y_max - y_min),\n",
    "                segmentation=[poly],\n",
    "                iscrowd=0)\n",
    "            annotations.append(data_anno)\n",
    "            obj_count += 1\n",
    "\n",
    "    coco_format_json = dict(\n",
    "        images=images,\n",
    "        annotations=annotations,\n",
    "        categories=[{\n",
    "            'id': 0,\n",
    "            'name': 'balloon'\n",
    "        }])\n",
    "    dump(coco_format_json, out_file)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    convert_balloon_to_coco(ann_file='data/balloon/train/via_region_data.json',\n",
    "                            out_file='data/balloon/train/annotation_coco.json',\n",
    "                            image_prefix='data/balloon/train')\n",
    "    convert_balloon_to_coco(ann_file='data/balloon/val/via_region_data.json',\n",
    "                            out_file='data/balloon/val/annotation_coco.json',\n",
    "                            image_prefix='data/balloon/val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tutorial/balloon_converter.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2. 准备配置文件**\n",
    "\n",
    "下载 `mask-rcnn_r50_fpn_1x_coco.py` 配置文件，并拷贝重命名为 `balloon`\n",
    "\n",
    "也可以尝试其他配置文件，如 `mask-rcnn_r50_fpn_mstrain-poly_3x_coco.py` 等，以比较不同的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mim download mmdet --config mask-rcnn_r50_fpn_1x_coco --dest tutorial/\n",
    "!cp tutorial/mask-rcnn_r50_fpn_1x_coco.py tutorial/balloon.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更改配置\n",
    "- 将检测头中的类别数改为 `1`\n",
    "    ```python\n",
    "    model = dict(\n",
    "        roi_head=dict(\n",
    "            bbox_head=dict(num_classes=1), mask_head=dict(num_classes=1)))\n",
    "    ```\n",
    "- 更改数据集相关配置\n",
    "    ```python\n",
    "    data_root = 'data/balloon/'\n",
    "    metainfo = {\n",
    "        'classes': ('balloon', ),\n",
    "        'palette': [\n",
    "            (220, 20, 60),\n",
    "        ]\n",
    "    }\n",
    "    train_dataloader = dict(\n",
    "        batch_size=1,\n",
    "        dataset=dict(\n",
    "            data_root=data_root,\n",
    "            metainfo=metainfo,\n",
    "            ann_file='train/annotation_coco.json',\n",
    "            data_prefix=dict(img='train/'))) # 图像应位于data_root/data_prefix下面\n",
    "    val_dataloader = dict(\n",
    "        dataset=dict(\n",
    "            data_root=data_root,\n",
    "            metainfo=metainfo,\n",
    "            ann_file='val/annotation_coco.json',\n",
    "            data_prefix=dict(img='val/')))\n",
    "    test_dataloader = val_dataloader\n",
    "    ```\n",
    "- 更改评价指标相关配置\n",
    "    ```python\n",
    "    val_evaluator = dict(ann_file=data_root + 'val/annotation_coco.json')\n",
    "    test_evaluator = val_evaluator\n",
    "    ```\n",
    "- 使用预训练的 Mask RCNN 模型\n",
    "    ```python\n",
    "    load_from = 'tutorial/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth'\n",
    "    ```\n",
    "- 更改 log 打印间隔为 `10`\n",
    "    ```python\n",
    "    default_hooks = dict(logger=dict(type='LoggerHook', interval=10))\n",
    "    ```\n",
    "- 更改学习率为 `0.02 / 8`\n",
    "    ```python\n",
    "    optim_wrapper = dict(optimizer=dict(lr=0.02 / 8))\n",
    "    ```\n",
    "- 更改验证间隔为 `4`\n",
    "    ```python\n",
    "    train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=12, val_interval=4)\n",
    "    ```\n",
    "- 更改权重存储间隔为 `4`\n",
    "    ```python\n",
    "    default_hooks = dict(checkpoint=dict(type='CheckpointHook', interval=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3. 使用工具开始训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mim train mmdet -l slurm -g 2 -G 2 -c 4 -p gpu tutorial/balloon.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4. 理解打印出来的 log 日志文件**\n",
    "+ 系统环境\n",
    "+ 配置文件\n",
    "+ 检查模型初始化记录\n",
    "+ 训练过程中学习率的变化、loss 变化、消耗时间、消耗内存\n",
    "+ 验证集上的结果"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5. 测试训练的模型，并保存结果文件**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mim test mmdet -l slurm -g 2 -G 2 -c 4 -p gpu tutorial/balloon.py --checkpoint work_dirs/balloon/epoch_12.pth --out tutorial/result_balloon.pkl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6. 测试训练好的模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python demo/image_demo.py data/balloon/train/7178882742_f090f3ce56_k.jpg tutorial/balloon.py --weights work_dirs/balloon/epoch_12.pth --out-dir tutorial/balloon_test/ --device cpu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Useful Tools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**运行工具 `mim run`**\n",
    "\n",
    "```bash\n",
    "mim run ${PACKAGE} ${COMMAND} --yes ${YES} --other_args ${OTHER_ARGS}\n",
    "```\n",
    "参数讲解：\n",
    "+ PACKAGE：工具包名\n",
    "+ COMMAND：运行命令的名字\n",
    "+ YES：不要求确认。bool类型的变量，默认为 True\n",
    "+ OTHER_ARGS: 其他传入各工具包运行命令的参数\n",
    "\n",
    "更多请参考：[链接](https://openmim.readthedocs.io/en/latest/api.html#module-mim.commands.run)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想查看某个工具包支持哪些命令以及使用方法，可使用命令：\n",
    "\n",
    "```bash\n",
    "mim run ${PACKAGE} -h\n",
    "```\n",
    "\n",
    "比如，查看 MMDetection 目前支持的命令："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mim run mmdet -h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Log Analysis\n",
    "根据训练log文件绘制`loss/mAP`曲线"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1. 安装依赖 `seaborn`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2. 绘制图像**\n",
    "```bash\n",
    "mim run mmdet analyze_logs plot_curve [--keys ${KEYS}] [--title ${TITLE}] [--legend ${LEGEND}] [--style ${STYLE}] [--out ${OUT_FILE}]\n",
    "```\n",
    "参数讲解：\n",
    "+ KEYS：需要绘制的所有参数，默认为`bbox_mAP`\n",
    "+ TITLE：图像标题\n",
    "+ LEGEND：图例\n",
    "+ STYLE：图像风格，默认为`dark`\n",
    "+ OUT_FILE：保存文件\n",
    "\n",
    "详情请参考：[链接](https://mmdetection.readthedocs.io/en/3.x/user_guides/useful_tools.html#log-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mim run mmdet analyze_logs plot_curve ${LOG_FILE} --keys loss_cls loss_bbox loss_mask lr time --legend loss_cls loss_bbox loss_mask lr time --out tutorial/log_analysis.png"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Result Analysis (有 Bug)\n",
    "计算每张图像的mAP并根据预测结果保存或展示分数最高和最低的图像"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "mim run mmdet analyze_results ${CONFIG} ${PREDICTION_PATH} ${SHOW_DIR} [--show] [--wait-time ${WAIT_TIME}] [--topk ${TOPK}] [--show-score-thr ${SHOW_SCORE_THR}]\n",
    "```\n",
    "参数讲解：\n",
    "+ CONFIG：模型配置文件路径\n",
    "+ PREDICTION_PATH：训练/测试输出的pickle格式结果文件\n",
    "+ SHOW_DIR：绘制的GT和检测图像的保存路径\n",
    "+ --show：是否展示绘制的图像，默认为`False`\n",
    "+ WAIT_TIME：展示间隔，`0`为阻隔，默认为`0`\n",
    "+ TOPK：排序后保存的分数最高和最低的图像个数，默认为`20`\n",
    "+ SHOW_SCORE_THR：展示的分数阈值，默认为`0`\n",
    "\n",
    "详情请参考：[链接](https://mmdetection.readthedocs.io/en/3.x/user_guides/useful_tools.html#result-analysis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于 `evaluation` 程序调整，需要修改一部分 `analyze_results` 代码\n",
    "    \n",
    "```python\n",
    "    if task == 'det':\n",
    "        # gt_instances = InstanceData()               \n",
    "        # gt_instances.bboxes = results[index]['gt_instances']['bboxes']\n",
    "        # gt_instances.labels = results[index]['gt_instances']['labels']\n",
    "\n",
    "        pred_instances = InstanceData()\n",
    "        pred_instances.bboxes = results[index]['pred_instances']['bboxes']\n",
    "        pred_instances.labels = results[index]['pred_instances']['labels']\n",
    "        pred_instances.scores = results[index]['pred_instances']['scores']\n",
    "\n",
    "        data_samples = DetDataSample()\n",
    "        data_samples.pred_instances = pred_instances\n",
    "        # data_samples.gt_instances = gt_instances\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mim run mmdet analyze_results tutorial/balloon.py tutorial/result_balloon.pkl tutorial/balloon_results\n",
    "!python tools/analysis_tools/analyze_results.py tutorial/balloon.py tutorial/result_balloon.pkl tutorial/balloon_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Browse Dataset\n",
    "直观地预览数据集（包括图像和边界框），并可以将图像保存到指定目录"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "mim run mmdet browse_dataset ${CONFIG} [--output-dir ${OUTPUT_DIR}] [--not-show] [--show-interval ${SHOW_INTERVAL}]\n",
    "```\n",
    "参数讲解：\n",
    "+ CONFIG：模型配置文件路径\n",
    "+ OUTPUT_DIR：需要保存时的存储路径\n",
    "+ --not-show：是否展示，默认为`False`\n",
    "+ SHOW_INTERVAL：展示间隔，默认为`2`\n",
    "\n",
    "详情请参考：[链接](https://mmdetection.readthedocs.io/en/3.x/user_guides/useful_tools.html#visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mim run mmdet browse_dataset tutorial/balloon.py --output-dir tutorial/balloon_vis --not-show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Error Analysis （有 Bug)\n",
    "按类别或其他标准分析COCO结果，并可将结果绘制成图像"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1. 修改配置文件**\n",
    "为了得到`bbox`和`segmentation`结果的`json`文件，需要对配置文件中的`test_evaluator`进行修改\n",
    "修改后的配置为\n",
    "```python\n",
    "test_evaluator = dict(\n",
    "    type='CocoMetric',\n",
    "    format_only=True, \n",
    "    metric=['bbox', 'segm'],\n",
    "    ann_file=data_root + 'val/annotation_coco.json',\n",
    "    outfile_prefix='tutorial/balloon_error/balloon'\n",
    ")\n",
    "```\n",
    "其中`format_only`用于指定`json`输出，`ann_file`用于给定标注文件，`outfile_prefix`用于制定输出文件的前缀"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2. 使用测试工具得到json结果**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mim test mmdet tutorial/balloon.py --checkpoint work_dirs/balloon/epoch_12.pth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3. 修改`coco_error_analysis`工具**\n",
    "因为我们使用了自定义的数据集进行模型的训练和测试，所以需要对`coco_error_analysis`工具进行一些调整\n",
    "```python\n",
    "    # child_catIds = gt.getCatIds(supNms=[nm['supercategory']])\n",
    "    # for idx, ann in enumerate(gt.dataset['annotations']):\n",
    "    #     if ann['category_id'] in child_catIds and ann['category_id'] != catId:\n",
    "    #         gt.dataset['annotations'][idx]['ignore'] = 1\n",
    "    #         gt.dataset['annotations'][idx]['iscrowd'] = 1\n",
    "    #         gt.dataset['annotations'][idx]['category_id'] = catId\n",
    "```\n",
    "注去如上部分的代码"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4. 使用`coco_error_analysis`工具进行错误分析**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "mim run mmdet coco_error_analysis ${RESULT} ${OUT_DIR} [-h] [--ann ${ANN}] [--types ${TYPES[TYPES...]}]\n",
    "```\n",
    "参数讲解：\n",
    "+ RESULT：测试结果文件\n",
    "+ OUT_DIR：保存结果分析图像的路径\n",
    "+ ANN：标注文件\n",
    "+ TYPES：结果格式，默认为`bbox`\n",
    "\n",
    "详情请参考：[链接](https://mmdetection.readthedocs.io/en/3.x/user_guides/useful_tools.html#error-analysis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到`bbox`的分析结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mim run mmdet coco_error_analysis tutorial/balloon_error/balloon.bbox.json tutorial/balloon_error --ann data/balloon/val/annotation_coco.json\n",
    "!python tools/analysis_tools/coco_error_analysis.py tutorial/balloon_error/balloon.bbox.json tutorial/balloon_error --ann data/balloon/val/annotation_coco.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到`segmentation`的分析结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mim run mmdet coco_error_analysis tutorial/balloon_error/balloon.segm.json tutorial/balloon_error --ann data/balloon/val/annotation_coco.json --types segm\n",
    "!python tools/analysis_tools/coco_error_analysis.py tutorial/balloon_error/balloon.segm.json tutorial/balloon_error --ann data/balloon/val/annotation_coco.json --types segm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Model Complexity\n",
    "计算给定模型的FLOPs和参数量"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "mim run mmdet get_flops ${CONFIG_FILE} [--shape ${INPUT_SHAPE}]\n",
    "```\n",
    "参数讲解：\n",
    "+ CONFIG_FILE：模型配置文件\n",
    "+ INPUT_SHAPE：指定输入形状\n",
    "\n",
    "详情请参考：[链接](https://mmdetection.readthedocs.io/en/3.x/user_guides/useful_tools.html#model-complexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mim run mmdet get_flops tutorial/balloon.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Confusion Matrix\n",
    "析预测结果并绘制混淆矩阵"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "mim run mmdet confusion_matrix ${CONFIG}  ${DETECTION_RESULTS}  ${SAVE_DIR} --show\n",
    "```\n",
    "参数讲解：\n",
    "+ CONFIG：模型配置文件\n",
    "+ IDETECTION_RESULTS：测试结果文件\n",
    "+ SAVE_DIR：储存路径\n",
    "+ --show：是否展示\n",
    "\n",
    "详情请参考：[链接](https://mmdetection.readthedocs.io/en/3.x/user_guides/useful_tools.html#confusion-matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先绘制balloon数据集的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mim run mmdet confusion_matrix tutorial/balloon.py tutorial/result_balloon.pkl tutorial/balloon_confusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于balloon数据集不包含多类别，再进行voc数据集结果的分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mim run mmdet confusion_matrix configs/pascal_voc/retinanet_r50_fpn_1x_voc0712.py tutorial/result_voc.pkl tutorial/voc_confusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
