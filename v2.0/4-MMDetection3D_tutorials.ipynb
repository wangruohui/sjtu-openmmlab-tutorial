{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/mmdet3d-logo.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [WIP] MMDetection3D 2.0 Tutorials\n",
    "\n",
    "<a href=\"\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MMDetection3D 2.0 Repo**：[https://github.com/open-mmlab/mmdetection3d](https://github.com/open-mmlab/mmdetection3d)\n",
    "\n",
    "**MMDetection3D 官方文档链接**：[https://mmdetection3d.readthedocs.io/en/latest/](https://mmdetection3d.readthedocs.io/en/latest/)\n",
    "\n",
    "**MMDetection3D 2.0 教学视频**：Coming Soon~\n",
    "\n",
    "**MMDetection3D 2.0 代码库介绍视频**：Coming Sonn~\n",
    "\n",
    "**加入微信社群方式**：关注公众号，选择 “加入我们” -> “微信社区”，即可获取入群二维码。非常期待你的到来呀~\n",
    "\n",
    "**作者**：OpenMMLab\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "0. Installation\n",
    "1. Inference\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1. 加载预置环境**\n",
    "\n",
    "我们已经在集群上预装了 OpenMMLab 2.0 环境，使用见 [1-SetupEnvironment.md#1-使用预置环境](1-SetupEnvironment.md#1-使用预置环境)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2. 下载 MMDetection3D 源码**\n",
    "\n",
    "虽然环境里面预装了一系列工具包，但我们也可以使用github上最新的代码。例如可以通过以下方式“覆盖”预装的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用国内的镜像\n",
    "!git clone https://github.com/open-mmlab/mmdetection3d -b dev-1.x\n",
    "# 重要，保证使用的是 clone 下来的版本\n",
    "%cd mmdetection3d\n",
    "# 重要，确保是 v2.0 版本\n",
    "!git checkout dev-1.x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3. 查看安装是否正确**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mmdet3d\n",
    "print(mmdet3d.__version__)\n",
    "print(mmdet3d.__file__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Preperation on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U openmim\n",
    "!mim install -U mmengine\n",
    "!mim install -U mmcv\n",
    "!mim install -U mmdet\n",
    "!git clone https://github.com/open-mmlab/mmdetection3d -b dev-1.x\n",
    "%cd mmdetection3d\n",
    "!pip install -v -e ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inference (New)\n",
    "用 MMDetection3D [模型库](https://mmdetection3d.readthedocs.io/en/latest/model_zoo.html)中预训练好的模型进行预测。\n",
    "\n",
    "Outline\n",
    "1. 3D Detection\n",
    "    1. Point cloud\n",
    "    2. Monocular 3D\n",
    "    3. Multi-modality\n",
    "2. 3D Segmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Point cloud 3D detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on KITTI data using PointPillars model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://download.openmmlab.com/mmdetection3d/v1.0.0_models/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-car/hv_pointpillars_secfpn_6x8_160e_kitti-3d-car_20220331_134606-d42d15ed.pth\n",
    "!python demo/pcd_demo.py \\\n",
    "    demo/data/kitti/000008.bin \\\n",
    "    configs/pointpillars/pointpillars_hv_secfpn_8xb6-160e_kitti-3d-car.py \\\n",
    "    hv_pointpillars_secfpn_6x8_160e_kitti-3d-car_20220331_134606-d42d15ed.pth \\\n",
    "    --show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on SUN RGB-D data using VoteNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://download.openmmlab.com/mmdetection3d/v1.0.0_models/votenet/votenet_16x8_sunrgbd-3d-10class/votenet_16x8_sunrgbd-3d-10class_20210820_162823-bf11f014.pth\n",
    "!python demo/pcd_demo.py \\\n",
    "    demo/data/sunrgbd/000017.bin \\\n",
    "    configs/votenet/votenet_8xb16_sunrgbd-3d.py \\\n",
    "    votenet_16x8_sunrgbd-3d-10class_20210820_162823-bf11f014.pth \\\n",
    "    --show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Monocular 3D detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on KITTI data using PGD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://download.openmmlab.com/mmdetection3d/v1.0.0_models/pgd/pgd_r101_caffe_fpn_gn-head_3x4_4x_kitti-mono3d/pgd_r101_caffe_fpn_gn-head_3x4_4x_kitti-mono3d_20211022_102608-8a97533b.pth\n",
    "!python demo/mono_det_demo.py \\\n",
    "    demo/data/kitti/000008.png \\\n",
    "    demo/data/kitti/000008.pkl \\\n",
    "    configs/pgd/pgd_r101-caffe_fpn_head-gn_4xb3-4x_kitti-mono3d.py \\\n",
    "    pgd_r101_caffe_fpn_gn-head_3x4_4x_kitti-mono3d_20211022_102608-8a97533b.pth \\\n",
    "    --show \\\n",
    "    --cam-type CAM2 \\\n",
    "    --score-thr 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on nuScenes data using FCOS3D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://download.openmmlab.com/mmdetection3d/v0.1.0_models/fcos3d/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune_20210717_095645-8d806dc2.pth\n",
    "!python demo/mono_det_demo.py \\\n",
    "    demo/data/nuscenes/n015-2018-07-24-11-22-45+0800__CAM_BACK__1532402927637525.jpg \\\n",
    "    demo/data/nuscenes/n015-2018-07-24-11-22-45+0800.pkl \\\n",
    "    configs/fcos3d/fcos3d_r101-caffe-dcn_fpn_head-gn_8xb2-1x_nus-mono3d_finetune.py \\\n",
    "    fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune_20210717_095645-8d806dc2.pth \\\n",
    "    --show \\\n",
    "    --cam-type CAM_BACK"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Multi-modality 3D detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on KITTI data using MVX-Net model (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://download.openmmlab.com/mmdetection3d/v1.0.0_models/mvxnet/dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-3class/dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-3class_20210831_060805-83442923.pth\n",
    "!python demo/multi_modality_demo.py \\\n",
    "    demo/data/kitti/000008.bin \\\n",
    "    demo/data/kitti/000008.png \\\n",
    "    demo/data/kitti/000008.pkl \\\n",
    "    configs/mvxnet/mvxnet_fpn_dv_second_secfpn_8xb2-80e_kitti-3d-3class.py \\\n",
    "    dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-3class_20210831_060805-83442923.pth \\\n",
    "    --cam-type CAM2 \\\n",
    "    --show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on SUN RGB-D data using ImVoteNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://download.openmmlab.com/mmdetection3d/v1.0.0_models/imvotenet/imvotenet_stage2_16x8_sunrgbd-3d-10class/imvotenet_stage2_16x8_sunrgbd-3d-10class_20210819_192851-1bcd1b97.pth\n",
    "!python demo/multi_modality_demo.py \\\n",
    "    demo/data/sunrgbd/000017.bin \\\n",
    "    demo/data/sunrgbd/000017.jpg \\\n",
    "    demo/data/sunrgbd/sunrgbd_000017_infos.pkl \\\n",
    "    configs/imvotenet/imvotenet_stage2_8xb16_sunrgbd-3d.py \\\n",
    "    imvotenet_stage2_16x8_sunrgbd-3d-10class_20210819_192851-1bcd1b97.pth \\\n",
    "    --cam-type CAM0 \\\n",
    "    --show \\\n",
    "    --score-thr 0.6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 3D Segmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on ScanNet data using PointNet++ (SSG) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://download.openmmlab.com/mmdetection3d/v0.1.0_models/pointnet2/pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-20class/pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-20class_20210514_143644-ee73704a.pth\n",
    "!python demo/pcd_seg_demo.py \\\n",
    "    demo/data/scannet/scene0000_00.bin \\\n",
    "    configs/pointnet2/pointnet2_ssg_2xb16-cosine-200e_scannet-seg.py \\\n",
    "    pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-20class_20210514_143644-ee73704a.pth \\\n",
    "    --show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inference Video"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### game.json\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"data_list\": [\n",
    "        {\n",
    "            \"images\": {\n",
    "                \"CAM_BACK\": {\n",
    "                    \"img_path\": \"game.png\",\n",
    "                    \"cam2img\": [\n",
    "                        [\n",
    "                            1000,\n",
    "                            0.0,\n",
    "                            683.0\n",
    "                        ],\n",
    "                        [\n",
    "                            0.0,\n",
    "                            1000,\n",
    "                            384.0\n",
    "                        ],\n",
    "                        [\n",
    "                            0.0,\n",
    "                            0.0,\n",
    "                            1.0\n",
    "                        ]\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet3d.apis import init_model\n",
    "\n",
    "config_file = 'configs/fcos3d/fcos3d_r101-caffe-dcn_fpn_head-gn_8xb2-1x_nus-mono3d_finetune.py'\n",
    "checkpoint_file = 'fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune_20210717_095645-8d806dc2.pth'\n",
    "\n",
    "model = init_model(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import mmengine\n",
    "from mmdet3d.apis import inference_mono_3d_detector\n",
    "from mmdet3d.registry import VISUALIZERS\n",
    "\n",
    "video = mmcv.VideoReader('game.mp4')\n",
    "ann_tmpl = 'game.json'\n",
    "tmp_out = 'tmp_out_game'\n",
    "frames = []\n",
    "cam_type = 'CAM_BACK'\n",
    "\n",
    "visualizer = VISUALIZERS.build(model.cfg.visualizer)\n",
    "visualizer.dataset_meta = model.dataset_meta\n",
    "\n",
    "# iterate over all frames\n",
    "for i, frame in enumerate(video):\n",
    "    imfn = f'game/{i:04d}.jpg'\n",
    "    mmcv.imwrite(frame, imfn)\n",
    "    \n",
    "    annfn = f'game/{i:04d}.json'\n",
    "    ann = mmengine.load(ann_tmpl)\n",
    "    ann['data_list'][0]['images']['CAM_BACK']['img_path'] = imfn\n",
    "    mmengine.dump(ann, annfn)\n",
    "    \n",
    "    img = mmcv.imread(imfn)\n",
    "    img = mmcv.imconvert(img, 'bgr', 'rgb')\n",
    "    data_input = dict(img=img)\n",
    "    out = 'tmp_out_' + imfn\n",
    "\n",
    "    result = inference_mono_3d_detector(model, imfn, annfn, cam_type)\n",
    "    visualizer.add_datasample(\n",
    "        'video',\n",
    "        data_input,\n",
    "        data_sample=result,\n",
    "        draw_gt=False,\n",
    "        show=False,\n",
    "        wait_time=0,\n",
    "        out_file=out,\n",
    "        pred_score_thr=0.15,\n",
    "        vis_task='mono_det')\n",
    "    \n",
    "    frames.append(f'{tmp_out}/{i:04d}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vwriter = cv2.VideoWriter('game-out.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 20.0, (1920,1080))\n",
    "\n",
    "for frame in frames:\n",
    "    img = cv2.imread(frame)\n",
    "    vwriter.write(img)\n",
    "\n",
    "vwriter.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b2859013d99487c261cd9552e4481075b4372d5070943a79343772cae642d30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
