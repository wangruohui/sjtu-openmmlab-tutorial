{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/mmdet3d-logo.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [WIP] MMDetection3D 2.0 Tutorials\n",
    "\n",
    "<a href=\"\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MMDetection3D 2.0 Repo**：[https://github.com/open-mmlab/mmdetection3d](https://github.com/open-mmlab/mmdetection3d)\n",
    "\n",
    "**MMDetection3D 官方文档链接**：[https://mmdetection3d.readthedocs.io/en/latest/](https://mmdetection3d.readthedocs.io/en/latest/)\n",
    "\n",
    "**MMDetection3D 2.0 教学视频**：Coming Soon~\n",
    "\n",
    "**MMDetection3D 2.0 代码库介绍视频**：Coming Sonn~\n",
    "\n",
    "**加入微信社群方式**：关注公众号，选择 “加入我们” -> “微信社区”，即可获取入群二维码。非常期待你的到来呀~\n",
    "\n",
    "**作者**：OpenMMLab\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "0. Installation\n",
    "1. Inference\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1. 加载预置环境**\n",
    "\n",
    "我们已经在集群上预装了 OpenMMLab 2.0 环境，使用见 [1-SetupEnvironment.md#1-使用预置环境](1-SetupEnvironment.md#1-使用预置环境)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2. 下载 MMDetection3D 源码**\n",
    "\n",
    "虽然环境里面预装了一系列工具包，但我们也可以使用github上最新的代码。例如可以通过以下方式“覆盖”预装的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用国内的镜像\n",
    "!git clone https://github.com/open-mmlab/mmdetection3d -b dev-1.x\n",
    "# 重要，保证使用的是 clone 下来的版本\n",
    "%cd mmdetection3d\n",
    "# 重要，确保是 v2.0 版本\n",
    "!git checkout dev-1.x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3. 查看安装是否正确**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmdet3d\n",
    "print(mmdet3d.__version__)\n",
    "print(mmdet3d.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inference \n",
    "用 MMDetection3D [模型库](https://mmdetection3d.readthedocs.io/en/latest/model_zoo.html)中预训练好的模型进行预测。\n",
    "\n",
    "Outline\n",
    "1. 3D Detection on Point Cloud & Image Data\n",
    "2. Monocular 3D Detection on Image Data\n",
    "3. 3D Segmentation on Point Cloud Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 3D Detection on Point Cloud & Image Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Single-modality"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on KITTI point cloud data using SECOND model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mim download mmdet3d --config second_hv_secfpn_8xb6-amp-80e_kitti-3d-3class --dest .\n",
    "!python demo/pcd_demo.py demo/data/kitti/000008.bin second_hv_secfpn_8xb6-amp-80e_kitti-3d-3class.py hv_second_secfpn_fp16_6x8_80e_kitti-3d-3class_20200925_110059-05f67bdf.pth --show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on SUN RGB-D point cloud data using VoteNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Multi-modality"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on KITTI point cloud & image data using MVX-Net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mim download mmdet3d --config dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-3class --dest .\n",
    "!python demo/multi_modality_demo.py demo/data/kitti/000008.bin demo/data/kitti/000008.png demo/data/kitti/000008.pkl dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-3class.py dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-3class_20210831_060805-83442923.pth --cam-type CAM2 --show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on SUN RGB-D point cloud & image data using ImVoteNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mim download mmdet3d --config imvotenet_stage2_16x8_sunrgbd-3d-10class --dest .\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Monocular 3D Detection on Image Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on nuScenes image data using FCOS3D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mim download mmdet3d --config fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune --dest .\n",
    "!python demo/mono_det_demo.py demo/data/kitti/000008.png demo/data/kitti/000008.pkl pgd_r101-caffe_fpn_head-gn_4xb3-4x_kitti-mono3d.py pgd_r101_caffe_fpn_gn-head_3x4_4x_kitti-mono3d_20211022_102608-8a97533b.pth --cam-type CAM2 --show --score 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 3D Segmentation on Point Cloud Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on ScanNet point cloud data using PointNet++ (SSG) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mim download mmdet3d --config pointnet2_msg_2xb16-cosine-250e_scannet-seg --dest .\n",
    "!python demo/pcd_seg_demo.py demo/data/scannet/scene0000_00.bin pointnet2_msg_2xb16-cosine-250e_scannet-seg.py pointnet2_msg_16x2_cosine_250e_scannet_seg-3d-20class_20210514_144009-24477ab1.pth --show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inference (New)\n",
    "用 MMDetection3D [模型库](https://mmdetection3d.readthedocs.io/en/latest/model_zoo.html)中预训练好的模型进行预测。\n",
    "\n",
    "Outline\n",
    "1. 3D Detection\n",
    "    1. Point cloud\n",
    "    2. Monocular 3D\n",
    "    3. Multi-modality\n",
    "2. 3D Segmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Point cloud 3D detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on KITTI data using PointPillars model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://download.openmmlab.com/mmdetection3d/v1.0.0_models/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-car/hv_pointpillars_secfpn_6x8_160e_kitti-3d-car_20220331_134606-d42d15ed.pth\n",
    "!python demo/pcd_demo.py demo/data/kitti/000008.bin configs/pointpillars/pointpillars_hv_secfpn_8xb6-160e_kitti-3d-car.py hv_pointpillars_secfpn_6x8_160e_kitti-3d-car_20220331_134606-d42d15ed.pth --show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on SUN RGB-D data using VoteNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://download.openmmlab.com/mmdetection3d/v1.0.0_models/votenet/votenet_16x8_sunrgbd-3d-10class/votenet_16x8_sunrgbd-3d-10class_20210820_162823-bf11f014.pth\n",
    "!python demo/pcd_demo.py demo/data/sunrgbd/sunrgbd_000017.bin configs/votenet/votenet_8xb16_sunrgbd-3d.py votenet_16x8_sunrgbd-3d-10class_20210820_162823-bf11f014.pth --show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Monocular 3D detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on KITTI data using PGD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://download.openmmlab.com/mmdetection3d/v1.0.0_models/pgd/pgd_r101_caffe_fpn_gn-head_3x4_4x_kitti-mono3d/pgd_r101_caffe_fpn_gn-head_3x4_4x_kitti-mono3d_20211022_102608-8a97533b.pth\n",
    "!python demo/mono_det_demo.py demo/data/kitti/000008.png demo/data/kitti/000008.pkl  configs/pgd/pgd_r101-caffe_fpn_head-gn_4xb3-4x_kitti-mono3d.py pgd_r101_caffe_fpn_gn-head_3x4_4x_kitti-mono3d_20211022_102608-8a97533b.pth  --show --cam-type CAM2 --score-thr 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on nuScenes data using FCOS3D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://download.openmmlab.com/mmdetection3d/v0.1.0_models/fcos3d/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune_20210717_095645-8d806dc2.pth\n",
    "!python demo/mono_det_demo.py demo/data/nuscenes/n015-2018-07-24-11-22-45+0800__CAM_BACK__1532402927637525.jpg demo/data/nuscenes/n015-2018-07-24-11-22-45+0800.pkl  configs/fcos3d/fcos3d_r101-caffe-dcn_fpn_head-gn_8xb2-1x_nus-mono3d_finetune.py fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune_20210717_095645-8d806dc2.pth  --show --cam-type CAM_BACK"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Multi-modality 3D detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on KITTI data using MVX-Net model (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://download.openmmlab.com/mmdetection3d/v1.0.0_models/mvxnet/dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-3class/dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-3class_20210831_060805-83442923.pth\n",
    "!python demo/multi_modality_demo.py demo/data/kitti/000008.bin demo/data/kitti/000008.png demo/data/kitti/000008.pkl configs/mvxnet/mvxnet_fpn_dv_second_secfpn_8xb2-80e_kitti-3d-3class.py dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-3class_20210831_060805-83442923.pth --cam-type CAM2 --show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on SUN RGB-D data using ImVoteNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://download.openmmlab.com/mmdetection3d/v1.0.0_models/imvotenet/imvotenet_stage2_16x8_sunrgbd-3d-10class/imvotenet_stage2_16x8_sunrgbd-3d-10class_20210819_192851-1bcd1b97.pth\n",
    "!python demo/multi_modality_demo.py demo/data/sunrgbd/000017.bin demo/data/sunrgbd/000017.jpg demo/data/sunrgbd/sunrgbd_000017_infos.pkl configs/imvotenet/imvotenet_stage2_8xb16_sunrgbd-3d.py imvotenet_stage2_16x8_sunrgbd-3d-10class_20210819_192851-1bcd1b97.pth --cam-type CAM0 --show --score-thr 0.6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 3D Segmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example on ScanNet data using PointNet++ (SSG) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://download.openmmlab.com/mmdetection3d/v0.1.0_models/pointnet2/pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-20class/pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-20class_20210514_143644-ee73704a.pth\n",
    "!python demo/pcd_seg_demo.py demo/data/scannet/scene0000_00.bin configs/pointnet2/pointnet2_ssg_2xb16-cosine-200e_scannet-seg.py pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-20class_20210514_143644-ee73704a.pth --show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inference Video"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### game.json\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"data_list\": [\n",
    "        {\n",
    "            \"images\": {\n",
    "                \"CAM_BACK\": {\n",
    "                    \"img_path\": \"game.png\",\n",
    "                    \"cam2img\": [\n",
    "                        [\n",
    "                            1000,\n",
    "                            0.0,\n",
    "                            683.0\n",
    "                        ],\n",
    "                        [\n",
    "                            0.0,\n",
    "                            1000,\n",
    "                            384.0\n",
    "                        ],\n",
    "                        [\n",
    "                            0.0,\n",
    "                            0.0,\n",
    "                            1.0\n",
    "                        ]\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet3d.apis import init_model\n",
    "\n",
    "config_file = 'configs/fcos3d/fcos3d_r101-caffe-dcn_fpn_head-gn_8xb2-1x_nus-mono3d_finetune.py'\n",
    "checkpoint_file = 'fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune_20210717_095645-8d806dc2.pth'\n",
    "\n",
    "model = init_model(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import mmengine\n",
    "from mmdet3d.apis import inference_mono_3d_detector\n",
    "from mmdet3d.registry import VISUALIZERS\n",
    "\n",
    "video = mmcv.VideoReader('game.mp4')\n",
    "ann_tmpl = 'game.json'\n",
    "tmp_out = 'tmp_out_game'\n",
    "frames = []\n",
    "cam_type = 'CAM_BACK'\n",
    "\n",
    "visualizer = VISUALIZERS.build(model.cfg.visualizer)\n",
    "visualizer.dataset_meta = model.dataset_meta\n",
    "\n",
    "# iterate over all frames\n",
    "for i, frame in enumerate(video):\n",
    "    imfn = f'game/{i:04d}.jpg'\n",
    "    mmcv.imwrite(frame, imfn)\n",
    "    \n",
    "    annfn = f'game/{i:04d}.json'\n",
    "    ann = mmengine.load(ann_tmpl)\n",
    "    ann['data_list'][0]['images']['CAM_BACK']['img_path'] = imfn\n",
    "    mmengine.dump(ann, annfn)\n",
    "    \n",
    "    img = mmcv.imread(imfn)\n",
    "    img = mmcv.imconvert(img, 'bgr', 'rgb')\n",
    "    data_input = dict(img=img)\n",
    "    out = 'tmp_out_' + imfn\n",
    "\n",
    "    result = inference_mono_3d_detector(model, imfn, annfn, cam_type)\n",
    "    visualizer.add_datasample(\n",
    "        'video',\n",
    "        data_input,\n",
    "        data_sample=result,\n",
    "        draw_gt=False,\n",
    "        show=False,\n",
    "        wait_time=0,\n",
    "        out_file=out,\n",
    "        pred_score_thr=0.15,\n",
    "        vis_task='mono_det')\n",
    "    \n",
    "    frames.append(f'{tmp_out}/{i:04d}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vwriter = cv2.VideoWriter('game-out.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 20.0, (1920,1080))\n",
    "\n",
    "for frame in frames:\n",
    "    img = cv2.imread(frame)\n",
    "    vwriter.write(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b2859013d99487c261cd9552e4481075b4372d5070943a79343772cae642d30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
